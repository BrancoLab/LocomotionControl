{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve decoding\n",
    "\n",
    "Analysis to see if you can decode left vs right turns from individual units in M2.\n",
    "\n",
    "\n",
    "\n",
    "For each curve ROI we get all the times the mouse crosses it and the associated firing rate (as a function of position relative to the axis).\n",
    "Then for each unit we use a logistic regression model to try and decode if the mouse went left/right through the curve from the firing rates alone. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from fcutils.progress import track\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(r\"C:\\Users\\Federico\\Documents\\GitHub\\pysical_locomotion\")\n",
    "\n",
    "from fcutils.plot.figure import clean_axes\n",
    "from fcutils.plot.elements import plot_mean_and_error\n",
    "from fcutils.maths.signals import rolling_mean\n",
    "from analysis.ephys.utils import get_recording_names, get_data, get_session_bouts, curves, get_roi_crossings\n",
    "\n",
    "save_folder = Path(r\"D:\\Dropbox (UCL)\\Rotation_vte\\Writings\\THESIS\\Chpt4\\Plots\")\n",
    "\n",
    "# print all available recordings\n",
    "TARGET = \"CUN/PPN\"\n",
    "print(get_recording_names(region=TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frate(spikes, s, bins):\n",
    "    \"\"\"\n",
    "        Given the s position at each frame and the frame at which spikes occurred during a ROI crossing,\n",
    "        get firing rate wrt position relative to the apex.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_visits_per_bin = np.histogram(s, bins=bins)[0]\n",
    "\n",
    "    spikes_positions = [s[spike] for spike in spikes]\n",
    "    nspikes_per_bin = np.histogram(spikes_positions, bins=bins)[0]\n",
    "\n",
    "    spikes_positions = rolling_mean(spikes_positions, 5)\n",
    "    nspikes_per_bin = rolling_mean(nspikes_per_bin, 5)\n",
    "\n",
    "    frates = nspikes_per_bin / n_visits_per_bin * 60\n",
    "    frates[np.isnan(frates)] = 0.0\n",
    "    frates[np.isinf(frates)] = 0.0  # a spike but no frame count?\n",
    "    return frates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 2\n",
    "bins = np.arange(-20, 20+ds, step=ds)\n",
    "\n",
    "\n",
    "data = {\n",
    "    **dict(\n",
    "        name=[],  # recording name\n",
    "        unit_id=[],  # unit id\n",
    "        brainregion=[],  # brain region\n",
    "        direction=[],  # direction (out/in)\n",
    "        roi = [],  # ROI name\n",
    "        label=[],  # left, right or straight\n",
    "    ),\n",
    "    **{s:[] for s in bins[1:]}  # firing rate at each S position bin\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = {}\n",
    "for REC in track(get_recording_names(region=TARGET)):\n",
    "    # fetch recording data\n",
    "    \n",
    "    alldata[REC] =  get_data(REC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_direction = dict(\n",
    "    first=dict(out=\"right\", _in=\"left\"),\n",
    "    second=dict(out=\"right\", _in=\"left\"),\n",
    "    third=dict(out=\"left\", _in=\"right\"),\n",
    "    fourth=dict(out=\"left\", _in=\"right\"),\n",
    ")\n",
    "\n",
    "\n",
    "for REC in get_recording_names(region=TARGET):\n",
    "    # fetch recording data\n",
    "    # units, left_fl, right_fl, left_hl, right_hl, body = get_data(REC)\n",
    "    units, left_fl, right_fl, left_hl, right_hl, body = alldata[REC]\n",
    "\n",
    "    if units is None or not len(units):\n",
    "        continue\n",
    "    \n",
    "    if TARGET == \"MOs\":\n",
    "        units = units.loc[units.brain_region.isin([\"MOs\", \"MOs1\", \"MOs2/3\", \"MOs5\", \"MOs6a\", \"MOs6b\"])]\n",
    "    else:\n",
    "        units = units.loc[units.brain_region.isin([\"CUN\", \"PPN\"])]\n",
    "        \n",
    "\n",
    "    out_bouts     = get_session_bouts(REC, complete=None)\n",
    "    in_bouts      = get_session_bouts(REC, direction=\"inbound\", complete=None)\n",
    "    out_crossings = {curve:get_roi_crossings(out_bouts, curve, ds=20, direction=\"out\") for curve in curves.keys()}\n",
    "    in_crossings  = {curve:get_roi_crossings(in_bouts, curve, ds=20, direction=\"in\") for curve in curves.keys()}\n",
    "\n",
    "    for (i, unit) in units.iterrows():\n",
    "        for curve in (\"second\", \"third\", \"fourth\"):\n",
    "            for (direction, crossings, bouts) in ((\"out\", out_crossings[curve], out_bouts), (\"_in\", in_crossings[curve], in_bouts)):\n",
    "                sign = 1 if direction == \"out\" else -1\n",
    "\n",
    "                for i, cross in crossings.iterrows():\n",
    "\n",
    "                    # get spikes at each bin\n",
    "                    bout = bouts.iloc[cross.bout_idx]\n",
    "                    s = sign * (curves[curve].s - np.array(bout.s[cross.enter_frame:cross.exit_frame]))\n",
    "                    spikes = unit.spikes[(unit.spikes > cross.session_start_frame)&(unit.spikes < cross.session_end_frame)] - cross.session_start_frame\n",
    "\n",
    "                    # get firing rate\n",
    "                    cross_frate = frate(spikes, s, bins)\n",
    "\n",
    "                    # store all data\n",
    "                    data[\"name\"].append(REC)\n",
    "                    data[\"unit_id\"].append(unit.unit_id)\n",
    "                    data[\"brainregion\"].append(unit.brain_region)\n",
    "                    data[\"direction\"].append(direction)\n",
    "                    data[\"roi\"].append(curve)\n",
    "                    data[\"label\"].append(curve_direction[curve][direction])\n",
    "                    for i, bin in enumerate(bins[1:]):\n",
    "                        data[bin].append(cross_frate[i])\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label each row by the unit/recording it belongs to\n",
    "data[\"identifier\"] = data[\"name\"] + \"+unit_\" + data[\"unit_id\"].astype(str)\n",
    "n_units = len(data.identifier.unique())\n",
    "print(n_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model\n",
    "For each unit, try to predict L/R turn from the firing rate of the unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables columns\n",
    "data = data.join(pd.get_dummies(data[[\"label\", \"direction\"]]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED = \"label_right\"\n",
    "\n",
    "select_cols = list(bins[1:]) + [PREDICTED]\n",
    "\n",
    "results, shuffled_accuracies = {}, []\n",
    "\n",
    "for unit in track(data.identifier.unique()):\n",
    "\n",
    "    \n",
    "    # sample L/R trials to get equal number of trials per direction\n",
    "    unit_data = data.loc[data.identifier == unit]\n",
    "    name = unit_data.name.iloc[0]\n",
    "    if name in tuned_recs:  # if not exists run the kinematics analysis cells\n",
    "        continue\n",
    "    side_counts = unit_data.groupby([\"label\"])[\"name\"].count()\n",
    "\n",
    "    try:\n",
    "        n_selected = min(side_counts[\"left\"], side_counts[\"right\"])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if n_selected < 10:\n",
    "        continue\n",
    "    \n",
    "    left = unit_data.loc[unit_data.label == \"left\"].sample(n_selected)\n",
    "    right = unit_data.loc[unit_data.label == \"right\"].sample(n_selected)\n",
    "\n",
    "    # keep bins + label column\n",
    "    unit_data = pd.concat([left, right])[select_cols].reset_index(drop=True)\n",
    "\n",
    "    # split train/test\n",
    "    X = unit_data.drop(PREDICTED, axis=1)\n",
    "    y = unit_data[PREDICTED]\n",
    "\n",
    "    # standardize columns of X\n",
    "    X = (X - X.mean()) / (X.std() + 0.0001)\n",
    "\n",
    "    # skip units with no spikes\n",
    "    # if np.max(X.mean().values) < .5:\n",
    "    #     continue\n",
    "\n",
    "    # fit the model with 5x k-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf.get_n_splits(X)\n",
    "    kf_accuracies = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # scale data\n",
    "        # scaler = StandardScaler()\n",
    "        # scaler.fit(X_train)\n",
    "        # X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "        # fit model\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X_train, y_train)\n",
    "        kf_accuracies.append(logreg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # fit model on randomly shuffled labels\n",
    "    # split X in train/test\n",
    "    X_train, X_test, _, _ = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "    unit_shuffled_accuracies = []\n",
    "    for i in range(100):\n",
    "        y_shuffled = y.sample(frac=1, random_state=i)\n",
    "        _, _, y_shuff_train, y_shuff_test = train_test_split(X, y_shuffled, test_size=0.3, random_state=0)\n",
    "\n",
    "        shuffled_logreg = LogisticRegression()\n",
    "        shuffled_logreg.fit(X_train, y_shuff_train)\n",
    "\n",
    "        acc = shuffled_logreg.score(X_test, y_shuff_test)\n",
    "        shuffled_accuracies.append(acc)\n",
    "        unit_shuffled_accuracies.append(acc)\n",
    "\n",
    "    # check if the model is significantly better than the shuffled labels\n",
    "    tuned = np.mean(kf_accuracies) > np.percentile(unit_shuffled_accuracies, 99)\n",
    "\n",
    "    results[unit] = dict(\n",
    "        name=name,\n",
    "        identifier=unit,\n",
    "        model=logreg,\n",
    "        accuracy=np.mean(kf_accuracies),\n",
    "        # scaler=scaler,\n",
    "        tuned = tuned,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "\n",
    "    )\n",
    "\n",
    "    # if len(results.keys()) > 100:\n",
    "    #     break\n",
    "\n",
    "print(f\"Succesfully fit {len(results.keys())} models for {n_units}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "plot accuracy histograma and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = TARGET if TARGET == \"MOs\" else \"CUN_PPN\"\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 9))\n",
    "\n",
    "accuracies = [r[\"accuracy\"] for r in results.values()]\n",
    "\n",
    "axes[0].hist(shuffled_accuracies, density=True, bins=20, alpha=.5, color=[.75, .75, .75], label=\"shuffled\")\n",
    "axes[0].hist(shuffled_accuracies, density=True, bins=20, lw=2, histtype=\"step\", color=[.75, .75, .75])\n",
    "axes[0].hist(accuracies, density=True, bins=20, alpha=.5, color=\"k\", label=\"data\")\n",
    "axes[0].hist(accuracies, density=True, bins=20, lw=2, histtype=\"step\", color=\"k\")\n",
    "axes[0].legend()\n",
    "\n",
    "# for res in results.values():\n",
    "#     logit_roc_auc = roc_auc_score(res['y_test'], logreg.predict(res['X_test']))\n",
    "#     fpr, tpr, thresholds = roc_curve(res['y_test'], logreg.predict_proba(res['X_test'])[:,1])\n",
    "\n",
    "#     axes[1].plot(fpr, tpr, color=\"k\", alpha=.5)\n",
    "\n",
    "axes[0].set(xlabel=\"Accuracy\", ylabel=\"Count\", title=f\"Predicting: {PREDICTED}\", xlim=[-0.05, 1.05])\n",
    "axes[0].axvline(0.5, lw=2, color=\"r\", ls=\"--\")\n",
    "axes[1].plot([0, 1], [0, 1],'r--', lw=2)\n",
    "_ = axes[1].set(xlabel='False Positive Rate', ylabel='True Positive Rate', title='Receiver operating characteristic')\n",
    "\n",
    "# save figure\n",
    "f.savefig(save_folder / f\"LR_decoding_{TARGET}_accuracy_hist.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.array(accuracies)\n",
    "above_66 = len(accuracies[accuracies >= 0.6])\n",
    "above_90 = len(accuracies[accuracies >= 0.9])\n",
    "print(f\"{above_66}/{len(accuracies)} ({round(above_66/len(accuracies) * 100, 2)}%) units have accuracy > 60%\")\n",
    "print(f\"{above_90}/{len(accuracies)} ({round(above_90/len(accuracies) * 100, 2)}%) units have accuracy > 90%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of tuned units as bar plot\n",
    "f, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "N = len(results.keys())\n",
    "n_tuned = len([r for r in results.values() if r[\"tuned\"]])\n",
    "\n",
    "print(f\"Fraction tuned: {n_tuned/N} - {n_tuned}/{N}\")\n",
    "\n",
    "ax.bar(0, n_tuned/N, color=\"k\")\n",
    "ax.bar(0, (N - n_tuned)/N, bottom=(n_tuned)/N, color=[.75, .75, .75])\n",
    "_ = ax.set(xlim=[-2, 2], ylabel=\"Fraction tuned\", xlabel=TARGET)\n",
    "ax.axhline(.5)\n",
    "\n",
    "\n",
    "f.savefig(save_folder / f\"LR_decoding_{TARGET}_n_tuned.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of accuracy for tuned vs non-tuned units\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "tuned_accuracies = [r[\"accuracy\"] for r in results.values() if r[\"tuned\"]]\n",
    "untuned_accuracies = [r[\"accuracy\"] for r in results.values() if not r[\"tuned\"]]\n",
    "\n",
    "# ax.hist(tuned_accuracies, density=True, bins=10, alpha=.5, color=\"k\", label=\"tuned\")\n",
    "# ax.hist(untuned_accuracies, density=True, bins=10, alpha=.5, color=\"red\", label=\"untuned\")\n",
    "\n",
    "sns.kdeplot(tuned_accuracies, shade=True, ax=ax, color=\"k\", bw_method=.25, label=\"tuned\")\n",
    "sns.kdeplot(untuned_accuracies, shade=True, ax=ax, color=\"red\", bw_method=.25, label=\"untuned\")\n",
    "\n",
    "\n",
    "ax.axvline(.5)\n",
    "ax.set(xlim=[0, 1], xlabel=\"Accuracy\", ylabel=\"Density\", xticks=[0, .25, .5, .75, 1])\n",
    "_ = ax.legend()\n",
    "\n",
    "f.savefig(save_folder / f\"LR_decoding_{TARGET}_accuracy_tunedvsuntuned_KDE.svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot example unit\n",
    "\n",
    "Plot firing rate over position for an example tuned unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "def upsample_frames_to_ms(var):\n",
    "    \"\"\"\n",
    "        Interpolates the values of a variable expressed in frams (60 fps)\n",
    "        to values expressed in milliseconds.\n",
    "    \"\"\"\n",
    "    t_60fps = np.arange(len(var)) / 60\n",
    "    f = interpolate.interp1d(t_60fps, var)\n",
    "\n",
    "    t_1000fps = np.arange(0, t_60fps[-1], step=1/1000)\n",
    "    # t_200fps = np.arange(0, t_60fps[-1], step=1/200)\n",
    "    interpolated_variable_values = f(t_1000fps)\n",
    "    return interpolated_variable_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_firing_rate(spikes_train: np.ndarray, dt: int = 10):\n",
    "    \"\"\"\n",
    "        Computes the firing rate given a spikes train (wether there is a spike or not at each ms).\n",
    "        Using a gaussian kernel with standard deviation = dt/2 [dt is in ms]\n",
    "    \"\"\"\n",
    "    return gaussian_filter1d(spikes_train, dt)  * 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def add_colorbar(ax, im, cbar_label):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"15%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.set_label(cbar_label)\n",
    "    return cbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute firing rate through each curve for ech ROI and plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_ID = 10\n",
    "\n",
    "\n",
    "# sort units based on accuracy\n",
    "sorted_units = sorted(results.values(), key=lambda x: x[\"accuracy\"], reverse=True)\n",
    "\n",
    "best_unit = sorted_units[UNIT_ID]\n",
    "rec, unit = best_unit[\"identifier\"].split(\"+\")\n",
    "\n",
    "# load rec\n",
    "units, left_fl, right_fl, left_hl, right_hl, body = alldata[rec]\n",
    "out_bouts = get_session_bouts(rec, complete=None)\n",
    "in_bouts = get_session_bouts(rec, direction=\"inbound\", complete=None)\n",
    "\n",
    "out_crossings = {curve:get_roi_crossings(out_bouts, curve, ds=20, direction=\"out\") for curve in curves.keys()}\n",
    "in_crossings = {curve:get_roi_crossings(in_bouts, curve, ds=20, direction=\"in\") for curve in curves.keys()}\n",
    "\n",
    "# get unit data\n",
    "unit = units.loc[units.unit_id == int(unit.split(\"_\")[-1])].iloc[0]\n",
    "\n",
    "CURVES = (\"first\", \"second\", \"third\", \"fourth\")\n",
    "firing_rate_data = {\n",
    "    \"left\":{curv : dict(x=[], y=[], frate=[]) for curv in CURVES},\n",
    "    \"right\":{curv : dict(x=[], y=[], frate=[]) for curv in CURVES},\n",
    "}\n",
    "\n",
    "for i, curve in enumerate(CURVES):\n",
    "    crossings_out = out_crossings[curve]\n",
    "    crossings_in = in_crossings[curve]\n",
    "\n",
    "    for c, crossings in enumerate([crossings_out, crossings_in]):\n",
    "        for _, cross in crossings.iterrows():\n",
    "            bout = out_bouts.iloc[cross.bout_idx] if c  == 0 else in_bouts.iloc[cross.bout_idx]\n",
    "\n",
    "            # get XY coord\n",
    "            X = np.array(bout.x[cross.enter_frame:cross.exit_frame])\n",
    "            Y = np.array(bout.y[cross.enter_frame:cross.exit_frame])\n",
    "\n",
    "            # get spikes  & position in milliseconds\n",
    "            spikes = unit.spikes[(unit.spikes > cross.session_start_frame)&(unit.spikes < cross.session_end_frame)] - cross.session_start_frame\n",
    "\n",
    "            time_frames = np.zeros(int(cross.session_end_frame - cross.session_start_frame))\n",
    "            time_frames[spikes.astype(np.int)] = 1\n",
    "\n",
    "            spike_ms = upsample_frames_to_ms(time_frames)\n",
    "            spike_ms[spike_ms < np.max(spike_ms)] = 0  # make sure it's binary\n",
    "            x_ms = upsample_frames_to_ms(X)\n",
    "            y_ms = upsample_frames_to_ms(Y)\n",
    "            frate = calc_firing_rate(spike_ms, dt=200)\n",
    "\n",
    "            # store data\n",
    "            side = list(curve_direction[curve].values())[c]\n",
    "            firing_rate_data[side][curve][\"x\"].extend(x_ms)\n",
    "            firing_rate_data[side][curve][\"y\"].extend(y_ms)\n",
    "            firing_rate_data[side][curve][\"frate\"].extend(frate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot an example unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_shift = [15, 24, 15,  5, ]\n",
    "y_shift = [0, 0,  0,  10,]\n",
    "\n",
    "# get unit data\n",
    "best_unit = sorted_units[10]\n",
    "rec, unit = best_unit[\"identifier\"].split(\"+\")\n",
    "units, left_fl, right_fl, left_hl, right_hl, body = alldata[rec]\n",
    "unit = units.loc[units.unit_id == int(unit.split(\"_\")[-1])].iloc[0]\n",
    "\n",
    "# plot a heatmap of the firing rate at each curve in each direction\n",
    "f, axes = plt.subplots(2, 2, figsize=(16, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "vmax = [40, 40]\n",
    "\n",
    "for i, side in enumerate((\"left\", \"right\")):\n",
    "    cmap = \"Reds\" if i == 0 else \"Blues\"\n",
    "    for j, curve in enumerate(CURVES):\n",
    "\n",
    "        dx = x_shift[j] if i == 1 else 0\n",
    "        dy = y_shift[j] if i == 1 else 0\n",
    "\n",
    "        x = np.array(firing_rate_data[side][curve][\"x\"]) + dx\n",
    "        y = np.array(firing_rate_data[side][curve][\"y\"]) + dy\n",
    "        frate = np.array(firing_rate_data[side][curve][\"frate\"]) \n",
    "        \n",
    "        # time_frames = np.zeros(int(cross.session_end_frame - cross.session_start_frame))\n",
    "        # time_frames[spikes.astype(np.int)] = 1\n",
    "        # spike_ms = upsample_frames_to_ms(time_frames)\n",
    "        # frate = calc_firing_rate(spike_ms, dt=100) / 1000\n",
    "\n",
    "\n",
    "        im = axes[j].hexbin(x, y, frate, cmap=cmap, gridsize=[10, 15], mincnt=50, vmin=0, vmax=vmax[i])\n",
    "\n",
    "        # add colorbar\n",
    "        if j == 0 and i == 0:\n",
    "            add_colorbar(axes[0], im, \"Firing rate (Hz)\")\n",
    "\n",
    "        if j == 1 and i == 1:\n",
    "            add_colorbar(axes[2], im, \"Firing rate (Hz)\")\n",
    "\n",
    "\n",
    "# save figure \n",
    "# f.savefig(f\"{save_folder}/LR_decoding_example_{TARGET}_{unit.unit_id}_firing_rate.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze differences in the kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_direction = dict(\n",
    "    first=dict(out=\"right\", _in=\"left\"),\n",
    "    second=dict(out=\"right\", _in=\"left\"),\n",
    "    third=dict(out=\"left\", _in=\"right\"),\n",
    "    fourth=dict(out=\"left\", _in=\"right\"),\n",
    ")\n",
    "\n",
    "\n",
    "speeds = {}\n",
    "\n",
    "for rec in alldata.keys():\n",
    "    print(f\"Doing {rec}\")\n",
    "    out_bouts = get_session_bouts(rec, complete=None)\n",
    "    in_bouts = get_session_bouts(rec, direction=\"inbound\", complete=None)\n",
    "\n",
    "    out_crossings = {curve:get_roi_crossings(out_bouts, curve, ds=20, direction=\"out\") for curve in curves.keys()}\n",
    "    in_crossings = {curve:get_roi_crossings(in_bouts, curve, ds=20, direction=\"in\") for curve in curves.keys()}\n",
    "    \n",
    "    rec_speed = dict(left=[], right=[])\n",
    "    for i, curve in enumerate((\"second\", \"third\", \"fourth\")):\n",
    "        crossings_out = out_crossings[curve]\n",
    "        crossings_in = in_crossings[curve]\n",
    "\n",
    "        for c, crossings in enumerate([crossings_out, crossings_in]):\n",
    "            for _, cross in crossings.iterrows():\n",
    "                bout = out_bouts.iloc[cross.bout_idx] if c  == 0 else in_bouts.iloc[cross.bout_idx]\n",
    "\n",
    "                # get XY coord\n",
    "                speed = np.array(bout.speed[cross.enter_frame:cross.exit_frame])\n",
    "                side = list(curve_direction[curve].values())[c]\n",
    "                rec_speed[side].extend(speed)\n",
    "    speeds[rec] = rec_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "for rec, s in speeds.items():\n",
    "    ax.hist(s[\"left\"], bins=np.arange(0, 60, 1), color=\"red\", alpha=0.5)\n",
    "    ax.hist(s[\"right\"], bins=np.arange(0, 60, 1), color=\"black\", alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic on speed traces\n",
    "Prep data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bin_x_by_y(\n",
    "    data: pd.DataFrame,\n",
    "    x: str,\n",
    "    y: str,\n",
    "    bins: np.ndarray = 10,\n",
    "    min_count: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "        Bins the values in a column X of a dataframe by bins\n",
    "        specified based on the values of another column Y\n",
    "    \"\"\"\n",
    "\n",
    "    # get bins\n",
    "    data[\"bins\"], bins = pd.cut(data[y], bins=bins, retbins=True)\n",
    "    data = data.loc[data.bins != np.nan]\n",
    "    bins_centers = (\n",
    "        bins[0] + np.cumsum(np.diff(bins)) - abs(np.diff(bins)[0] / 2)\n",
    "    )\n",
    "\n",
    "    # get values\n",
    "    mu = data.groupby(\"bins\")[x].mean()\n",
    "    sigma = data.groupby(\"bins\")[x].std()\n",
    "    counts = data.groupby(\"bins\")[x].count()\n",
    "\n",
    "    return bins_centers, mu, sigma, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_direction = dict(\n",
    "    second=dict(out=\"right\", _in=\"left\"),\n",
    "    third=dict(out=\"left\", _in=\"right\"),\n",
    "    fourth=dict(out=\"left\", _in=\"right\"),\n",
    ")\n",
    "\n",
    "\n",
    "ds = 2\n",
    "bins = np.arange(-20, 20+ds, step=ds)\n",
    "\n",
    "\n",
    "data = {\n",
    "    **dict(\n",
    "        name=[],  # recording name\n",
    "        direction=[],  # direction (out/in)\n",
    "        label=[],  # left, right or straight\n",
    "        nunits = [],\n",
    "    ),\n",
    "    **{s:[] for s in bins[1:]}  # firing rate at each S position bin\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for REC in get_recording_names(region=TARGET):\n",
    "    # fetch recording data\n",
    "    # units, left_fl, right_fl, left_hl, right_hl, body = get_data(REC)\n",
    "    units, left_fl, right_fl, left_hl, right_hl, body = alldata[REC]\n",
    "\n",
    "    if units is None or not len(units):\n",
    "        continue\n",
    "    \n",
    "    if TARGET == \"MOs\":\n",
    "        units = units.loc[units.brain_region.isin([\"MOs\", \"MOs1\", \"MOs2/3\", \"MOs5\", \"MOs6a\", \"MOs6b\"])]\n",
    "    else:\n",
    "        units = units.loc[units.brain_region.isin([\"CUN\", \"PPN\"])]\n",
    "        \n",
    "\n",
    "    out_bouts     = get_session_bouts(REC, complete=None)\n",
    "    in_bouts      = get_session_bouts(REC, direction=\"inbound\", complete=None)\n",
    "    out_crossings = {curve:get_roi_crossings(out_bouts, curve, ds=20, direction=\"out\") for curve in curves.keys()}\n",
    "    in_crossings  = {curve:get_roi_crossings(in_bouts, curve, ds=20, direction=\"in\") for curve in curves.keys()}\n",
    "\n",
    "    for curve in (\"second\", \"third\", \"fourth\"):\n",
    "        for (direction, crossings, bouts) in ((\"out\", out_crossings[curve], out_bouts), (\"_in\", in_crossings[curve], in_bouts)):\n",
    "            sign = 1 if direction == \"out\" else -1\n",
    "\n",
    "            for i, cross in crossings.iterrows():\n",
    "\n",
    "                # get spikes at each bin\n",
    "                bout = bouts.iloc[cross.bout_idx]\n",
    "                s = sign * (curves[curve].s - np.array(bout.s[cross.enter_frame:cross.exit_frame]))\n",
    "\n",
    "                # get binned speed\n",
    "                speed = np.array(bout.speed[cross.enter_frame:cross.exit_frame])             \n",
    "                _, binned_speed, _, _ = bin_x_by_y(\n",
    "                    pd.DataFrame(dict(s=s, speed=speed)),\n",
    "                    \"speed\", \"s\", bins=bins\n",
    "                )\n",
    "\n",
    "                # store all data\n",
    "                data[\"name\"].append(REC)\n",
    "                data[\"direction\"].append(direction)\n",
    "                data[\"label\"].append(curve_direction[curve][direction])\n",
    "                data[\"nunits\"].append(len(units))\n",
    "                for i, bin in enumerate(bins[1:]):\n",
    "                    data[bin].append(binned_speed[i])\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data = data.join(pd.get_dummies(data[[\"label\", \"direction\"]]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED = \"label_right\"\n",
    "results, shuffled_accuracies = {}, []\n",
    "select_cols = list(bins[1:]) + [PREDICTED]\n",
    "units_explained_away_by_speed = 0\n",
    "tot_units = 0\n",
    "for rec in track(data['name'].unique()):\n",
    "    # sample L/R trials to get equal number of trials per direction\n",
    "    rec_data = data.loc[data['name'] == rec]\n",
    "    name = rec_data.name.iloc[0]\n",
    "\n",
    "    side_counts = rec_data.groupby([\"label\"])[\"name\"].count()\n",
    "\n",
    "    try:\n",
    "        n_selected = min(side_counts[\"left\"], side_counts[\"right\"])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if n_selected < 12:\n",
    "        continue\n",
    "    \n",
    "    left = rec_data.loc[rec_data.label == \"left\"].sample(n_selected)\n",
    "    right = rec_data.loc[rec_data.label == \"right\"].sample(n_selected)\n",
    "\n",
    "    # keep bins + label column\n",
    "    rec_data = pd.concat([left, right])[select_cols].reset_index(drop=True).dropna()\n",
    "\n",
    "    # split train/test\n",
    "    X = rec_data.drop(PREDICTED, axis=1)\n",
    "    y = rec_data[PREDICTED]\n",
    "\n",
    "    # standardize columns of X\n",
    "    X = (X - X.mean()) / (X.std() + 0.0001)\n",
    "\n",
    "\n",
    "    # fit the model with 5x k-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf.get_n_splits(X)\n",
    "    kf_accuracies = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # fit model\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X_train, y_train)\n",
    "        kf_accuracies.append(logreg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # fit model on randomly shuffled labels\n",
    "    # split X in train/test\n",
    "    X_train, X_test, _, _ = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "    rec_shuffled_accuracies = []\n",
    "    for i in range(100):\n",
    "        y_shuffled = y.sample(frac=1, random_state=i)\n",
    "        _, _, y_shuff_train, y_shuff_test = train_test_split(X, y_shuffled, test_size=0.3, random_state=0)\n",
    "\n",
    "        shuffled_logreg = LogisticRegression()\n",
    "        shuffled_logreg.fit(X_train, y_shuff_train)\n",
    "\n",
    "        acc = shuffled_logreg.score(X_test, y_shuff_test)\n",
    "        shuffled_accuracies.append(acc)\n",
    "        rec_shuffled_accuracies.append(acc)\n",
    "\n",
    "    # check if the model is significantly better than the shuffled labels\n",
    "    tuned = np.mean(kf_accuracies) > np.percentile(rec_shuffled_accuracies, 99)\n",
    "\n",
    "\n",
    "    n_units = data.loc[data['name'] == rec][\"nunits\"].iloc[0]\n",
    "    tot_units += n_units\n",
    "    if tuned:\n",
    "        units_explained_away_by_speed += n_units\n",
    "\n",
    "    results[rec] = dict(\n",
    "        name=name,\n",
    "        model=logreg,\n",
    "        accuracy=np.mean(kf_accuracies),\n",
    "        # scaler=scaler,\n",
    "        tuned = tuned,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "\n",
    "    )\n",
    "\n",
    "    # if len(results.keys()) > 100:\n",
    "    #     break\n",
    "\n",
    "print(f\"Succesfully fit {len(results.keys())} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{units_explained_away_by_speed}/{tot_units} ({units_explained_away_by_speed/tot_units*100}) units explained away by speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of which recordings are tuned\n",
    "tuned_recs = [rec for rec, res in results.items() if res[\"tuned\"]]\n",
    "tuned_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of tuned units as bar plot\n",
    "f, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "N = len(results.keys())\n",
    "n_tuned = len([r for r in results.values() if r[\"tuned\"]])\n",
    "\n",
    "print(f\"Fraction tuned: {n_tuned/N} - {n_tuned}/{N}\")\n",
    "\n",
    "ax.bar(0, n_tuned/N, color=\"k\")\n",
    "ax.bar(0, (N - n_tuned)/N, bottom=(n_tuned)/N, color=[.75, .75, .75])\n",
    "_ = ax.set(xlim=[-2, 2], ylabel=\"Fraction tuned\", xlabel=TARGET)\n",
    "ax.axhline(.5)\n",
    "\n",
    "\n",
    "f.savefig(save_folder / f\"LR_decoding_{TARGET}_n_tuned_BEAHAV_ONLY.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze speed tuning\n",
    "\n",
    "Take low/high locomotion speed frames when the mouse is not turning and do a logistic regression to see if you can tell from neural activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def upsample_frames_to_ms(var):\n",
    "    \"\"\"\n",
    "        Interpolates the values of a variable expressed in frams (60 fps)\n",
    "        to values expressed in milliseconds.\n",
    "    \"\"\"\n",
    "    t_60fps = np.arange(len(var)) / 60\n",
    "    f = interpolate.interp1d(t_60fps, var)\n",
    "\n",
    "    t_1000fps = np.arange(0, t_60fps[-1], step=1 / 1000)\n",
    "    # t_200fps = np.arange(0, t_60fps[-1], step=1/200)\n",
    "    interpolated_variable_values = f(t_1000fps)\n",
    "    return interpolated_variable_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = {}\n",
    "\n",
    "for REC in get_recording_names(region=TARGET):\n",
    "    # fetch recording data\n",
    "    # units, left_fl, right_fl, left_hl, right_hl, body = get_data(REC)\n",
    "    units, left_fl, right_fl, left_hl, right_hl, body = alldata[REC]\n",
    "    \n",
    "    # get tracking data\n",
    "    recdata = pd.DataFrame({\n",
    "        k: upsample_frames_to_ms(body[k]) for k in (\"speed\", \"global_coord\", \"angular_velocity\")\n",
    "    })\n",
    "\n",
    "\n",
    "    # get spike times of each unit\n",
    "    for i, unit in units.iterrows():\n",
    "        spikes = np.zeros_like(body.speed)\n",
    "        spike_times = unit.spikes\n",
    "        spike_times = spike_times[spike_times < len(spikes)]\n",
    "        spikes[spike_times] = 1\n",
    "        spikes = upsample_frames_to_ms(spikes)\n",
    "        spikes[spikes < np.max(spikes)] = 0\n",
    "        recdata[f\"{unit['name']}_{unit.unit_id}\"] = gaussian_filter1d(spikes, sigma=100) * 1000\n",
    "\n",
    "\n",
    "    # keep only when not turning too much\n",
    "    recdata = recdata.loc[\n",
    "        (recdata.angular_velocity > -500) & (recdata.angular_velocity < 500) \n",
    "    ]\n",
    "\n",
    "    # split between slow/fast\n",
    "    slow = recdata.loc[(recdata.speed > 5)&(recdata.speed < 20)]\n",
    "    fast = recdata.loc[recdata.speed > 40]\n",
    "    n_samples = np.min([len(fast), len(slow)]) - 1\n",
    "\n",
    "    if n_samples < 1000: continue\n",
    "    slow = slow.sample(n_samples)\n",
    "    fast = fast.sample(n_samples)\n",
    "\n",
    "    slow[\"speed_class\"] = \"slow\"\n",
    "    fast[\"speed_class\"] = \"fast\"\n",
    "\n",
    "    data = pd.concat([slow, fast])\n",
    "    data = data.join(pd.get_dummies(data[\"speed_class\"]))\n",
    "    regression_data[REC] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting FC_210715_AAA1110750_r5_hairpin\n",
      "Fitting FC_210716_AAA1110750_r6_hairpin\n",
      "Fitting FC_210720_AAA1110750_hairpin\n",
      "Fitting FC_210721_AAA1110750_hairpin\n",
      "Fitting FC_210722_AAA1110750_hairpin\n",
      "Fitting FC_211022_BAA110516_hairpin\n",
      "Fitting FC_211027_BAA110516_hairpin\n",
      "Fitting FC_211214_BAA110517_hairpin\n",
      "Fitting FC_220114_BAA110517_hairpin\n",
      "Fitting FC_210830_BAA1110281_hairpin\n",
      "Fitting FC_210831_BAA1110281_hairpin\n",
      "Fitting FC_210901_BAA1110281_hairpin\n",
      "Fitting FC_210906_BAA1110281_hairpin\n"
     ]
    }
   ],
   "source": [
    "results = dict(\n",
    "    tuned = [],\n",
    ")\n",
    "for rec, data in regression_data.items():\n",
    "    print(f\"Fitting {rec}\")\n",
    "    data = data.reset_index(drop=True).dropna()\n",
    "    data = data.drop(['speed', 'global_coord', 'angular_velocity', 'speed_class', 'slow'], axis=1)\n",
    "\n",
    "    # split train/test\n",
    "    X = data.drop([\"fast\"], axis=1)\n",
    "    y = data[\"fast\"]\n",
    "\n",
    "    # standardize columns of X\n",
    "    X = (X - X.mean()) / (X.std() + 0.0001)\n",
    "\n",
    "    for n, unit in enumerate(X.columns):\n",
    "        # print(f\"Fitting {n+1}/{len(X.columns)}\")\n",
    "        x = X[unit]\n",
    "\n",
    "        # fit the model with 5x k-fold cross-validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        kf.get_n_splits(x)\n",
    "        kf_accuracies = []\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # fit model\n",
    "            logreg = LogisticRegression()\n",
    "            logreg.fit(X_train.values.reshape(-1, 1), y_train.values)\n",
    "            kf_accuracies.append(logreg.score(X_test.values.reshape(-1, 1), y_test.values))\n",
    "\n",
    "\n",
    "        # fit model on randomly shuffled labels\n",
    "        # split X in train/test\n",
    "        X_train, X_test, _, _ = train_test_split(x, y, test_size=.3, random_state=0)\n",
    "        rec_shuffled_accuracies = []\n",
    "        for i in range(100):\n",
    "            y_shuffled = y.sample(frac=1, random_state=i)\n",
    "            _, _, y_shuff_train, y_shuff_test = train_test_split(X, y_shuffled, test_size=0.3, random_state=0)\n",
    "\n",
    "            shuffled_logreg = LogisticRegression()\n",
    "            shuffled_logreg.fit(X_train.values.reshape(-1, 1), y_shuff_train.values)\n",
    "\n",
    "            acc = shuffled_logreg.score(X_test.values.reshape(-1, 1), y_shuff_test.values)\n",
    "            rec_shuffled_accuracies.append(acc)\n",
    "\n",
    "        # check if the model is significantly better than the shuffled labels\n",
    "        tuned = np.mean(kf_accuracies) > np.percentile(rec_shuffled_accuracies, 99)\n",
    "        results[\"tuned\"].append(tuned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction tuned: 0.7727272727272727 - 374/484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Figure</span><span style=\"color: #000000; text-decoration-color: #000000\"> size 1152x648 with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\"> Axes</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 1152x648 with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAIWCAYAAAB9WCFxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAffUlEQVR4nO3df7Bnd13f8dfbxARbCahZBbOJCTVaVkUJa4pDO00ENcnYxB9Rk5YKiKb+wF+1OqE40EmdQbDqjDaCETFClRBA6FIXggoRtYTJBkMgidE1BbMBTQgYEJCw+O4f97v65ebeu9+7uef++PB4zNzZ7znfc7/3nZw5u/vc7znnW90dAAAA2Ok+a6sHAAAAgI0gcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYwvFbPcB6nXzyyX366adv9RgAAABM4KabbvpAd+86lu/dcYF7+umn58CBA1s9BgAAABOoqvce6/c6RRkAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIUwWuFX10qq6p6revcrzVVW/VFUHq+qWqjprqlkAAAAY35Tv4F6d5Lw1nj8/yZmzr8uSvGjCWQAAABjcZIHb3W9N8sE1Nrkoyct6yQ1JHllVj55qHgAAAMa2ldfgnpLkrrnlQ7N1AAAAsG7Hb/UAi6iqy7J0GnNOO+20LZ4GgCOuv/76rR4BNsQ555yz1SMAsAG28h3cu5OcOre8e7buQbr7qu7e2917d+3atSnDAQAAsLNsZeDuS/Lds7spPzHJ/d39/i2cBwAAgB1sslOUq+oVSc5JcnJVHUryvCSfnSTd/eIk+5NckORgko8lecZUswAAADC+yQK3uy89yvOd5Iem+vkAAAB8ZtnKU5QBAABgwwhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIUwauFV1XlXdUVUHq+ryFZ4/rareUlV/WlW3VNUFU84DAADAuCYL3Ko6LsmVSc5PsifJpVW1Z9lmP53k2u5+fJJLkvzKVPMAAAAwtinfwT07ycHuvrO7H0hyTZKLlm3TSU6aPX5EkvdNOA8AAAADmzJwT0ly19zyodm6ef8tyVOr6lCS/Ul+eKUXqqrLqupAVR249957p5gVAACAHW6rbzJ1aZKru3t3kguSvLyqHjRTd1/V3Xu7e++uXbs2fUgAAAC2vykD9+4kp84t756tm/fMJNcmSXe/LcnDkpw84UwAAAAMasrAvTHJmVV1RlWdkKWbSO1bts1fJXlyklTVY7MUuM5BBgAAYN0mC9zuPpzkWUmuS3J7lu6WfGtVXVFVF842+4kk31dV70zyiiRP7+6eaiYAAADGdfyUL97d+7N086j5dc+de3xbkidNOQMAAACfGbb6JlMAAACwIQQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxh0s/BBWBs55577laPABuiu7d6BAA2gHdwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYwaeBW1XlVdUdVHayqy1fZ5jur6raqurWqfnvKeQAAABjX8VO9cFUdl+TKJN+Q5FCSG6tqX3ffNrfNmUmeneRJ3f2hqvrCqeYBAABgbFO+g3t2koPdfWd3P5DkmiQXLdvm+5Jc2d0fSpLuvmfCeQAAABjYlIF7SpK75pYPzdbN+7IkX1ZVf1JVN1TVeSu9UFVdVlUHqurAvffeO9G4AAAA7GSrnqJcVWet9Y3d/Y4N+vlnJjknye4kb62qr+ruv132s65KclWS7N27tzfg5wIAADCYta7B/fnZrw9LsjfJO5NUksclOZDk647y2ncnOXVuefds3bxDSd7e3Z9M8v+q6s+zFLw3LjQ9AAAAzKx6inJ3n9vd5yZ5f5Kzuntvdz8hyePz4FBdyY1JzqyqM6rqhCSXJNm3bJvXZend21TVyVk6ZfnO9f5HAAAAwCLX4H55d7/ryEJ3vzvJY4/2Td19OMmzklyX5PYk13b3rVV1RVVdONvsuiT3VdVtSd6S5Ce7+771/kcAAABAda99SWtVvSLJR5P8r9mq/5Dkc7v70olnW9HevXv7wIEDW/GjAVimqrZ6BNgQR/v7EACbp6pu6u69x/K9i3wO7jOS/ECSH50tvzXJi47lhwEAAMBUjhq43f33VfXiJPu7+45NmAkAAADW7ajX4M6ul705yRtny19TVctvFgUAAABbapGbTD0vydlJ/jZJuvvmJGdMNxIAAACs3yKB+8nuvn/ZOndiAAAAYFtZ5CZTt1bVv09yXFWdmeRHkvzfaccCAACA9VnkHdwfTvIVST6R5BVJPpzkxyacCQAAANZtkbsofyzJc2ZfAAAAsC0dNXCr6suS/Jckp89v391fP91YAAAAsD6LXIP7qiQvTvKSJJ+adhwAAAA4NosE7uHuftHkkwAAAMBDsMhNpl5fVT9YVY+uqs8/8jX5ZAAAALAOi7yD+7TZrz85t66TPGbjxwEAAIBjs8hdlM/YjEEAAADgoVjkLsrfvdL67n7Zxo8DAAAAx2aRU5S/du7xw5I8Ock7kghcAAAAto1FTlH+4fnlqnpkkmumGggAAACOxSJ3UV7uo0lclwsAAMC2ssg1uK/P0l2Tk6Ug3pPkVVMOBQAAAOu1yDW4/2Pu8eEk7+3uQxPNAwAAAMdkkVOUL+juP5x9/Ul3H6qqF0w+GQAAAKzDIoH7DSusO3+jBwEAAICHYtVTlKvqB5L8YJLHVNUtc089PMmfTD0YAAAArMda1+D+dpI3JHl+ksvn1n+kuz846VQAAACwTqsGbnffn+T+JJdu3jgAAABwbI7lc3ABAABg2xG4AAAADEHgAgAAMISjBm5VfVtV/UVV3V9VH66qj1TVhzdjOAAAAFjUWndRPuKFSf5dd98+9TAAAABwrBY5RflvxC0AAADb3SLv4B6oqlcmeV2STxxZ2d2/M9VQAAAAsF6LBO5JST6W5Bvn1nUSgQsAAMC2cdTA7e5nbMYgAAAA8FAschfl3VX12qq6Z/b1mqravRnDAQAAwKIWucnUbyTZl+SLZ1+vn60DAACAbWORwN3V3b/R3YdnX1cn2TXxXAAAALAuiwTufVX11Ko6bvb11CT3TT0YAAAArMcigfs9Sb4zyV8neX+Si5O48RQAAADbyiJ3UX5vkgs3YRYAAAA4ZqsGblX9VHe/sKp+OUufe/tpuvtHJp1sFXfe+9F816++bSt+NADLfNGlz9/qEWBD+LsFwBjWegf39tmvBzZjEAAAAHgoqvtBb85++gZV39Hdrzraus2yd+/ePnBAcwNsB1W11SPAhjja34cA2DxVdVN37z2W713kJlPPXnAdAAAAbJm1rsE9P8kFSU6pql+ae+qkJIenHgwAAADWY61rcN+XpetvL0xy09z6jyT58SmHAgAAgPVaNXC7+51J3llVr03y0e7+VJJU1XFJTtyk+QAAAGAhi1yD+6YknzO3/DlJfn+acQAAAODYLBK4D+vuvzuyMHv8z6YbCQAAANZvkcD9aFWddWShqp6Q5OPTjQQAAADrt9ZNpo74sSSvqqr3Jakkj0ryXVMOBQAAAOt11MDt7hur6l8m+fLZqju6+5PTjgUAAADrs8g7uMlS3O5J8rAkZ1VVuvtl040FAAAA63PUwK2q5yU5J0uBuz/J+Un+OInABQAAYNtY5CZTFyd5cpK/7u5nJPnqJI+YdCoAAABYp0UC9+Pd/Q9JDlfVSUnuSXLqtGMBAADA+ixyDe6Bqnpkkl9LclOSv0vytimHAgAAgPVaM3CrqpI8v7v/NsmLq+qNSU7q7ls2YzgAAABY1JqB291dVfuTfNVs+T2bMRQAAACs1yLX4L6jqr528kkAAADgIVjkGtx/leSpVfWeJB9NUll6c/dxUw4GAAAA67Fq4FbVad39V0m+aRPnAQAAgGOy1ju4r0tyVne/t6pe093fvkkzAQAAwLqtdQ1uzT1+zNSDAAAAwEOxVuD2Ko8BAABg21nrFOWvrqoPZ+md3M+ZPU7+6SZTJ00+HQAAACxo1cDt7uM2cxAAAAB4KBb5HFwAAADY9gQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAmDdyqOq+q7qiqg1V1+RrbfXtVdVXtnXIeAAAAxjVZ4FbVcUmuTHJ+kj1JLq2qPSts9/AkP5rk7VPNAgAAwPimfAf37CQHu/vO7n4gyTVJLlphu/+e5AVJ/n7CWQAAABjclIF7SpK75pYPzdb9o6o6K8mp3f27a71QVV1WVQeq6sC999678ZMCAACw423ZTaaq6rOS/EKSnzjatt19VXfv7e69u3btmn44AAAAdpwpA/fuJKfOLe+erTvi4Um+Msn1VfWeJE9Mss+NpgAAADgWUwbujUnOrKozquqEJJck2Xfkye6+v7tP7u7Tu/v0JDckubC7D0w4EwAAAIOaLHC7+3CSZyW5LsntSa7t7lur6oqqunCqnwsAAMBnpuOnfPHu3p9k/7J1z11l23OmnAUAAICxbdlNpgAAAGAjCVwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAQAAGILABQAAYAgCFwAAgCEIXAAAAIYgcAEAABiCwAUAAGAIkwZuVZ1XVXdU1cGqunyF5/9zVd1WVbdU1R9U1ZdMOQ8AAADjmixwq+q4JFcmOT/JniSXVtWeZZv9aZK93f24JK9O8sKp5gEAAGBsU76De3aSg919Z3c/kOSaJBfNb9Ddb+nuj80Wb0iye8J5AAAAGNiUgXtKkrvmlg/N1q3mmUneMOE8AAAADOz4rR4gSarqqUn2Jvm3qzx/WZLLkuS0007bxMkAAADYKaZ8B/fuJKfOLe+erfs0VfWUJM9JcmF3f2KlF+ruq7p7b3fv3bVr1yTDAgAAsLNNGbg3Jjmzqs6oqhOSXJJk3/wGVfX4JL+apbi9Z8JZAAAAGNxkgdvdh5M8K8l1SW5Pcm1331pVV1TVhbPNfi7J5yZ5VVXdXFX7Vnk5AAAAWNOk1+B29/4k+5ete+7c46dM+fMBAAD4zDHlKcoAAACwaQQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwBIELAADAEAQuAAAAQxC4AAAADEHgAgAAMASBCwAAwBAELgAAAEMQuAAAAAxB4AIAADAEgQsAAMAQBC4AAABDELgAAAAMQeACAAAwhEkDt6rOq6o7qupgVV2+wvMnVtUrZ8+/vapOn3IeAAAAxjVZ4FbVcUmuTHJ+kj1JLq2qPcs2e2aSD3X3lyb5xSQvmGoeAAAAxjblO7hnJznY3Xd29wNJrkly0bJtLkrym7PHr07y5KqqCWcCAABgUFMG7ilJ7ppbPjRbt+I23X04yf1JvmDCmQAAABjU8Vs9wCKq6rIkl80WP1FV797KeXhITk7yga0egmNi3+1s9t/OZd9tgglPILP/djb7b+ey73a2Lz/Wb5wycO9Ocurc8u7ZupW2OVRVxyd5RJL7lr9Qd1+V5KokqaoD3b13komZnP23c9l3O5v9t3PZdzub/bez2X87l323s1XVgWP93ilPUb4xyZlVdUZVnZDkkiT7lm2zL8nTZo8vTvLm7u4JZwIAAGBQk72D292Hq+pZSa5LclySl3b3rVV1RZID3b0vya8neXlVHUzywSxFMAAAAKzbpNfgdvf+JPuXrXvu3OO/T/Id63zZqzZgNLaO/bdz2Xc7m/23c9l3O5v9t7PZfzuXfbezHfP+K2cEAwAAMIIpr8EFAACATbPtA7eqfq6q/qyqbqmq11bVI1fZ7ryquqOqDlbV5Zs8Jquoqu+oqlur6h+qatU72VXVe6rqXVV180O5axobZx37zrG3DVXV51fV71XVX8x+/bxVtvvU7Li7uaqW3wiQTXS0Y6mqTqyqV86ef3tVnb4FY7KKBfbf06vq3rnj7Xu3Yk4erKpeWlX3rPYxlLXkl2b79paqOmuzZ2RlC+y7c6rq/rnj7rkrbcfWqKpTq+otVXXb7O+cP7rCNus+/rZ94Cb5vSRf2d2PS/LnSZ69fIOqOi7JlUnOT7InyaVVtWdTp2Q1707ybUneusC253b317il+7Zx1H3n2NvWLk/yB919ZpI/mC2v5OOz4+5ruvvCzRuPeQseS89M8qHu/tIkv5jkBZs7JatZx++Fr5w73l6yqUOylquTnLfG8+cnOXP2dVmSF23CTCzm6qy975Lkj+aOuys2YSYWdzjJT3T3niRPTPJDK/zeue7jb9sHbne/qbsPzxZvyNLn6S53dpKD3X1ndz+Q5JokF23WjKyuu2/v7ju2eg7Wb8F959jbvi5K8puzx7+Z5Fu2bhQWsMixNL9PX53kyVVVmzgjq/N74Q7W3W/N0qd5rOaiJC/rJTckeWRVPXpzpmMtC+w7trHufn93v2P2+CNJbk9yyrLN1n38bfvAXeZ7krxhhfWnJLlrbvlQHvw/h+2tk7ypqm6qqsu2ehgW5tjbvr6ou98/e/zXSb5ole0eVlUHquqGqvqWzRmNFSxyLP3jNrN/+L0/yRdsynQczaK/F3777BS7V1fVqZszGhvAn3U729dV1Tur6g1V9RVbPQwrm1128/gkb1/21LqPv0k/JmhRVfX7SR61wlPP6e7/PdvmOVl6G/u3NnM2jm6R/beAf93dd1fVFyb5var6s9m/yjGhDdp3bJG19t/8Qnd3Va12y/wvmR17j0ny5qp6V3f/5UbPCuT1SV7R3Z+oqv+UpXfjv36LZ4LRvSNLf879XVVdkOR1WTrVlW2kqj43yWuS/Fh3f/ihvt62CNzufspaz1fV05N8c5In98qfa3R3kvl/Cd09W8cmONr+W/A17p79ek9VvTZLp3sJ3IltwL5z7G2htfZfVf1NVT26u98/O5XnnlVe48ixd2dVXZ+lfz0VuJtvkWPpyDaHqur4JI9Ict/mjMdRHHX/dff8vnpJkhduwlxsDH/W7VDzsdTd+6vqV6rq5O7+wFbOxT+pqs/OUtz+Vnf/zgqbrPv42/anKFfVeUl+KsmF3f2xVTa7McmZVXVGVZ2Q5JIk7ga6Q1TVP6+qhx95nOQbs3SDI7Y/x972tS/J02aPn5bkQe/IV9XnVdWJs8cnJ3lSkts2bULmLXIsze/Ti5O8eZV/9GXzHXX/Lbtm7MIsXWvGzrAvyXfP7ub6xCT3z10CwjZWVY86cq+Cqjo7S+3jHwa3idm++fUkt3f3L6yy2bqPv23xDu5R/M8kJ2bptNUkuaG7v7+qvjjJS7r7gu4+XFXPSnJdkuOSvLS7b926kTmiqr41yS8n2ZXkd6vq5u7+pvn9l6VrA18727/HJ/nt7n7jlg1NksX2nWNvW/vZJNdW1TOTvDfJdyZJLX3k0/d39/cmeWySX62qf8jSH/o/290CdwusdixV1RVJDnT3viz9JeDlVXUwSzdVuWTrJmbegvvvR6rqwixdbvXBJE/fsoH5NFX1iiTnJDm5qg4leV6Sz06S7n5xkv1JLkhyMMnHkjxjayZluQX23cVJfqCqDif5eJJL/MPgtvKkJP8xybuq6ubZuv+a5LTk2I+/so8BAAAYwbY/RRkAAAAWIXABAAAYgsAFAABgCAIXAACAIQhcAAAAhiBwAWADzT538Zqq+suquqmq9lfVZVX1f5Ztd3VVXTx7fH1VHZh7bm9VXb9s+5uq6sSqek9VvauqbqmqN1XVo2bPr7X+NXOvc3FVXT3d/wEA2DoCFwA2yOxD61+b5Pru/hfd/YQkz87S530fzRdW1fmrvO4ZSe7u7k/MVp3b3Y9LciBLnxmYo6x/QlXtWed/DgDsOAIXADbOuUk+Oftw+iRJd78zyR8t8L0/l+Q5qzx3XpI3rrD+rUm+dIH1P7/GawPAMAQuAGycr0xy0zF+79uSPFBV567w3GqB+81J3rXA+muTnFVVK8UwAAxD4ALA9HrB9T+T5KfnV1TVCUl2d/edc6vfUlU3JzkpyfMXWP+pLL1D/Ox1Tw4AO8jxWz0AAAzk1iQXr7D+viSft2zd5yf5wPyK7n5zVf1MkifOrf43Sf542fee290fyIOttj5JXp6lwH33Ks8DwI7nHVwA2DhvTnJiVV12ZEVVPS7JFyT54qp67GzdlyT56iQ3r/AaP5Pkp+aWz0vyhoc6WHd/MskvJvnxh/paALBdCVwA2CDd3Um+NclTZh8TdGuWThV+X5KnJvmN2SnEr07yvd19/wqvsT/JvXOrzknyhxs04q/H2VsADKyW/iwGALabqtqd5Ne6e8WPDwIAPp3ABQAAYAhOUQYAAGAIAhcAAIAhCFwAAACGIHABAAAYgsAFAABgCAIXAACAIQhcAAAAhvD/ASGxfmHc8VHbAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the fraction of tuned units as a bar plot\n",
    "\n",
    "\n",
    "# Plot number of tuned units as bar plot\n",
    "f, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "N = len(results[\"tuned\"])\n",
    "n_tuned = sum(results[\"tuned\"])\n",
    "\n",
    "print(f\"Fraction tuned: {n_tuned/N} - {n_tuned}/{N}\")\n",
    "\n",
    "ax.bar(0, n_tuned/N, color=\"k\")\n",
    "ax.bar(0, (N - n_tuned)/N, bottom=(n_tuned)/N, color=[.75, .75, .75])\n",
    "_ = ax.set(xlim=[-2, 2], ylabel=\"Fraction tuned\", xlabel=TARGET)\n",
    "ax.axhline(.5)\n",
    "\n",
    "\n",
    "f.savefig(save_folder / f\"speed_decoding_{TARGET}_n_tuned.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('glm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "150ed04e4a7757279df9e34a7668d32a4de2f602328bc7aa115cd7824ea88d27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
