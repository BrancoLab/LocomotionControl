{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "After having prepared the data with `glm_data_prep`, load each recordings data, do a bit of cleaning and normalization and then save each units' data into a dedicated folder and as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from fcutils.path import to_yaml, from_yaml\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(r\"C:\\Users\\Federico\\Documents\\GitHub\\pysical_locomotion\")\n",
    "from analysis.ephys.utils import get_recording_names\n",
    "\n",
    "\n",
    "cache = Path(r\"D:\\Dropbox (UCL)\\Rotation_vte\\Locomotion\\analysis\\ephys\\GLM\\data\")\n",
    "base_dir = Path(r\"D:\\Dropbox (UCL)\\Rotation_vte\\Locomotion\\analysis\\ephys\\GLM\")\n",
    "\n",
    "metadatafile = base_dir / \"metadata.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "and remove rows with nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(REC):\n",
    "    rec_data = pd.read_hdf(cache / (REC + \"_bouts.h5\"), key=\"data\").reset_index(drop=True)\n",
    "    rec_data.head()\n",
    "\n",
    "    # drop rows with nans\n",
    "    rec_data.dropna(inplace=True)\n",
    "    return rec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and clean\n",
    "\n",
    "Improve on columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(rec_data):\n",
    "    units = [c for c in rec_data.columns if isinstance(c, int)]\n",
    "    variables = list(rec_data.columns[:17])\n",
    "\n",
    "    # rename unit columns\n",
    "    column_names = [c if c not in units else \"unit_\" + str(c) for c in rec_data.columns]\n",
    "    rec_data.rename(columns=dict(zip(rec_data.columns, column_names)), inplace=True)\n",
    "\n",
    "    # add squared variables\n",
    "    rec_data[\"v_squared\"] = rec_data.v**2\n",
    "    rec_data[\"omega_squared\"] = rec_data.omega**2\n",
    "    variables += [\"v_squared\", \"omega_squared\"]\n",
    "    return rec_data, units, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(rec_data, variables):\n",
    "    # split behavioral variables from units firing rates\n",
    "    X, FR = rec_data[variables], rec_data.drop(variables, axis=1)\n",
    "\n",
    "    # go from firing rate to p(spike | ms)\n",
    "    FR = FR / 1000\n",
    "\n",
    "    # normalize columns of X\n",
    "    X = pd.DataFrame(Normalizer().fit_transform(X.T).T, columns=X.columns, index=X.index)\n",
    "\n",
    "    # put everything back together\n",
    "    data = pd.concat([X, FR], axis=1)\n",
    "    del rec_data, X, FR\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "For each unit in a dedicated folder/file and update metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(REC, data, units):\n",
    "    metadata = from_yaml(metadatafile) or dict()\n",
    "    for i, unit in enumerate(units):\n",
    "        unit_folder = base_dir / f\"{REC}_unit_{unit}\"\n",
    "        if not unit_folder.exists():\n",
    "            unit_folder.mkdir()\n",
    "\n",
    "\n",
    "        unit_data = data[list(variables) + [f\"unit_{unit}\"]].copy()\n",
    "        unit_data.rename(columns={f\"unit_{unit}\":'p_spike'}, inplace=True)\n",
    "\n",
    "        unit_data.to_parquet(unit_folder / \"data.parquet\")\n",
    "\n",
    "\n",
    "        metadata[f\"{REC}_{unit}\"] = dict(\n",
    "            recording=REC,\n",
    "            unit=unit,\n",
    "            unit_data=str(unit_folder / \"data.parquet\"),\n",
    "            glm_fitted=False,\n",
    "        )\n",
    "    to_yaml(metadatafile, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC_220408_BAA1101192_hairpin not found\n",
      "(366168, 724)\n",
      "(333465, 724)\n",
      "[573, 558, 552, 428, 376, 366, 571]\n",
      "['s', 'sdot', 'v', 'dv_250ms', 'dv_500ms', 'dv_1000ms', 'omega', 'domega_250ms', 'domega_500ms', 'domega_1000ms', 'curv_0cm', 'curv_5cm', 'curv_10cm', 'curv_15cm', 'curv_20cm', 'curv_25cm', 'curv_30cm']\n",
      "(667131, 2441)\n",
      "(608937, 2441)\n",
      "[606, 410, 139, 141, 285, 414, 233, 223, 219, 212, 478, 461, 79, 107, 505, 321, 340, 80, 235, 87, 124, 117, 100, 289]\n",
      "['s', 'sdot', 'v', 'dv_250ms', 'dv_500ms', 'dv_1000ms', 'omega', 'domega_250ms', 'domega_500ms', 'domega_1000ms', 'curv_0cm', 'curv_5cm', 'curv_10cm', 'curv_15cm', 'curv_20cm', 'curv_25cm', 'curv_30cm']\n",
      "(332663, 4057)\n",
      "(294577, 4057)\n",
      "[590, 292, 280, 425, 572, 293, 545, 543, 554, 557, 562, 565, 567, 551, 417, 397, 400, 470, 481, 467, 387, 347, 357, 71, 75, 83, 88, 99, 174, 182, 183, 185, 262, 266, 273, 312, 320, 329, 375, 17]\n",
      "['s', 'sdot', 'v', 'dv_250ms', 'dv_500ms', 'dv_1000ms', 'omega', 'domega_250ms', 'domega_500ms', 'domega_1000ms', 'curv_0cm', 'curv_5cm', 'curv_10cm', 'curv_15cm', 'curv_20cm', 'curv_25cm', 'curv_30cm']\n",
      "(469587, 4259)\n",
      "(415916, 4259)\n",
      "[142, 295, 296, 302, 303, 305, 312, 620, 278, 624, 629, 632, 638, 650, 653, 657, 663, 627, 143, 567, 603, 139, 133, 132, 115, 610, 608, 120, 606, 141, 97, 89, 86, 532, 70, 559, 77, 251, 75, 28, 18, 6]\n",
      "['s', 'sdot', 'v', 'dv_250ms', 'dv_500ms', 'dv_1000ms', 'omega', 'domega_250ms', 'domega_500ms', 'domega_1000ms', 'curv_0cm', 'curv_5cm', 'curv_10cm', 'curv_15cm', 'curv_20cm', 'curv_25cm', 'curv_30cm']\n",
      "FC_220413_BAA1101192_hairpin not found\n",
      "FC_220414_BAA1101192_hairpin not found\n",
      "FC_220415_BAA1101192_hairpin not found\n",
      "FC_220432_BAA1101192_hairpin not found\n",
      "FC_220433_BAA1101192_hairpin not found\n",
      "FC_220434_BAA1101192_hairpin not found\n",
      "FC_220435_BAA1101192_hairpin not found\n"
     ]
    }
   ],
   "source": [
    "for REC in get_recording_names():\n",
    "    try:\n",
    "        rec_data = load(REC)\n",
    "    except:\n",
    "        print(f\"{REC} not found\")\n",
    "        continue\n",
    "    rec_data, units, variables = clean(rec_data)\n",
    "    data = normalize(rec_data, variables)\n",
    "    del rec_data\n",
    "    save(REC, data, units)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d14c38d234234b969aee73678d168700778a98933f098d78df9f79a7508c5a93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
